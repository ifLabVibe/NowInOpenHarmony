# Copyright (c) 2025 XBXyftx
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import requests
from bs4 import BeautifulSoup
import json
import re
import time
import logging
import hashlib
from urllib.parse import urljoin
from datetime import datetime
from typing import List, Dict, Optional, Callable

logger = logging.getLogger(__name__)

class OpenHarmonyBlogCrawler:
    """
    OpenHarmonyæŠ€æœ¯åšå®¢çˆ¬è™«
    çˆ¬å–OpenHarmonyå®˜ç½‘æŠ€æœ¯åšå®¢æ–‡ç« å†…å®¹
    """
    
    def __init__(self):
        self.base_url = "https://old.openharmony.cn"
        self.api_url = "https://old.openharmony.cn/backend/knowledge/secondaryPage/queryBatch"
        self.source = "OpenHarmonyæŠ€æœ¯åšå®¢"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Referer': 'https://old.openharmony.cn/',
            'Cache-Control': 'no-cache'
        })
        
    def get_page_content(self, url: str) -> Optional[str]:
        """è·å–é¡µé¢å†…å®¹"""
        try:
            response = self.session.get(url, timeout=15)
            response.raise_for_status()
            response.encoding = 'utf-8'
            return response.text
        except Exception as e:
            logger.warning(f"âš ï¸ [OpenHarmonyåšå®¢] è·å–é¡µé¢å¤±è´¥: {url}, é”™è¯¯: {e}")
            return None

    def get_all_blog_articles(self) -> List[Dict]:
        """
        åˆ†é¡µè·å–æ‰€æœ‰æŠ€æœ¯åšå®¢æ–‡ç« ä¿¡æ¯
        type=2 è¡¨ç¤ºæŠ€æœ¯åšå®¢ç±»å‹
        """
        all_articles = []
        page_num = 1
        page_size = 200  # æ ¹æ®ç”¨æˆ·è¦æ±‚è®¾ç½®ä¸º200
        total_pages = 1
        
        logger.info(f"ğŸš€ [OpenHarmonyåšå®¢] å¼€å§‹è·å–æŠ€æœ¯åšå®¢æ–‡ç« åˆ—è¡¨ï¼Œé¡µé¢å¤§å°: {page_size}")
        
        while page_num <= total_pages:
            try:
                # æ„é€ APIè¯·æ±‚URL
                api_url = f"{self.api_url}?type=2&pageNum={page_num}&pageSize={page_size}"
                logger.info(f"ğŸ“¡ [OpenHarmonyåšå®¢] è¯·æ±‚ç¬¬ {page_num} é¡µ: {api_url}")
                
                response = self.session.get(api_url, timeout=15)
                response.raise_for_status()
                
                data = response.json()
                
                # æ£€æŸ¥å“åº”æ ¼å¼
                if data.get("code") != 0:
                    logger.error(f"âŒ [OpenHarmonyåšå®¢] APIè¿”å›é”™è¯¯: {data.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                    break
                
                articles = data.get("data", [])
                total_pages = data.get("totalPage", 1)
                total_num = data.get("totalNum", 0)
                
                logger.info(f"ğŸ“„ [OpenHarmonyåšå®¢] ç¬¬ {page_num}/{total_pages} é¡µï¼Œæœ¬é¡µ {len(articles)} ç¯‡æ–‡ç« ï¼Œæ€»è®¡ {total_num} ç¯‡")
                
                if not articles:
                    logger.info(f"ğŸ“‹ [OpenHarmonyåšå®¢] ç¬¬ {page_num} é¡µæ— æ•°æ®ï¼Œåœæ­¢è·å–")
                    break
                
                # å¤„ç†æ–‡ç« æ•°æ®
                for article in articles:
                    try:
                        article_info = self._extract_article_info(article)
                        if article_info:
                            all_articles.append(article_info)
                    except Exception as e:
                        logger.warning(f"âš ï¸ [OpenHarmonyåšå®¢] è§£ææ–‡ç« ä¿¡æ¯å¤±è´¥: {e}")
                        continue
                
                page_num += 1
                
                # æ·»åŠ è¯·æ±‚é—´éš”ï¼Œé¿å…è¿‡äºé¢‘ç¹
                time.sleep(0.5)
                
            except Exception as e:
                logger.error(f"âŒ [OpenHarmonyåšå®¢] è·å–ç¬¬ {page_num} é¡µå¤±è´¥: {e}")
                break
        
        logger.info(f"âœ… [OpenHarmonyåšå®¢] å…±è·å–åˆ° {len(all_articles)} ç¯‡æœ‰æ•ˆæ–‡ç« ä¿¡æ¯")
        return all_articles

    def _extract_article_info(self, article_data: Dict) -> Optional[Dict]:
        """ä»APIå“åº”ä¸­æå–æ–‡ç« ä¿¡æ¯"""
        try:
            # æå–åŸºæœ¬ä¿¡æ¯
            title = article_data.get("title", "").strip()
            url = article_data.get("url", "").strip()
            content_summary = article_data.get("content", "").strip()
            start_time = article_data.get("startTime", "")
            
            # éªŒè¯å¿…è¦å­—æ®µ
            if not title or not url:
                logger.warning(f"âš ï¸ [OpenHarmonyåšå®¢] æ–‡ç« ç¼ºå°‘å¿…è¦å­—æ®µ: title={title}, url={url}")
                return None
            
            # å¤„ç†æ—¥æœŸæ ¼å¼
            formatted_date = self._format_date(start_time)
            
            return {
                "title": title,
                "url": url,
                "date": formatted_date,
                "summary": content_summary
            }
            
        except Exception as e:
            logger.error(f"âŒ [OpenHarmonyåšå®¢] æå–æ–‡ç« ä¿¡æ¯å¤±è´¥: {e}")
            return None

    def _format_date(self, date_str: str) -> str:
        """æ ¼å¼åŒ–æ—¥æœŸå­—ç¬¦ä¸²"""
        try:
            if not date_str:
                return datetime.now().strftime('%Y-%m-%d')
            
            # å¤„ç†å¸¸è§çš„æ—¥æœŸæ ¼å¼
            if '.' in date_str:
                # æ ¼å¼: 2024.06.06
                date_str = date_str.replace('.', '-')
            
            # å°è¯•è§£ææ—¥æœŸ
            try:
                parsed_date = datetime.strptime(date_str, '%Y-%m-%d')
                return parsed_date.strftime('%Y-%m-%d')
            except ValueError:
                # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å­—ç¬¦ä¸²
                return date_str
                
        except Exception as e:
            logger.warning(f"âš ï¸ [OpenHarmonyåšå®¢] æ—¥æœŸæ ¼å¼åŒ–å¤±è´¥: {date_str}, é”™è¯¯: {e}")
            return datetime.now().strftime('%Y-%m-%d')

    def parse_article_content(self, article_url: str) -> List[Dict]:
        """
        è§£ææ–‡ç« å†…å®¹ï¼Œä»¿ç…§OpenHarmonyçˆ¬è™«çš„é€»è¾‘
        """
        content = self.get_page_content(article_url)
        if not content:
            logger.warning(f"âš ï¸ [OpenHarmonyåšå®¢] æ— æ³•è·å–æ–‡ç« å†…å®¹: {article_url}")
            return []
        
        soup = BeautifulSoup(content, 'html.parser')
        result_data = []
        
        # å°è¯•å¤šç§å®¹å™¨é€‰æ‹©å™¨ï¼Œä»¿ç…§åŸæœ‰é€»è¾‘
        article_container = (
            soup.find(id='js_content') or
            soup.find(class_='rich_media_content') or
            soup.find(id='page-content') or
            soup.find(class_='rich_media_area_primary') or
            soup.find(class_=re.compile(r'article|content|detail|main', re.I)) or
            soup.find('article') or
            soup.find(id=re.compile(r'article|content|detail|main', re.I)) or
            soup.find(class_='content') or
            soup.find(class_='article-content')
        )
        
        if not article_container:
            article_container = soup.find('body')
            logger.info(f"ğŸ“„ [OpenHarmonyåšå®¢] ä½¿ç”¨bodyä½œä¸ºæ–‡ç« å®¹å™¨: {article_url}")
        
        if article_container:
            # è§£æå„ç§å…ƒç´ ç±»å‹
            for element in article_container.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'div', 'img', 'video', 'pre', 'code']):
                try:
                    if element.name in ['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'div']:
                        text = element.get_text().strip()
                        if text and len(text) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„æ–‡æœ¬
                            result_data.append({"type": "text", "value": text})
                    
                    elif element.name == 'img':
                        img_src = element.get('data-src') or element.get('data-original') or element.get('src')
                        if img_src:
                            img_url = urljoin(self.base_url, img_src)
                            result_data.append({"type": "image", "value": img_url})
                    
                    elif element.name == 'video':
                        video_src = element.get('src')
                        if video_src:
                            video_url = urljoin(self.base_url, video_src)
                            result_data.append({"type": "video", "value": video_url})
                        
                        # å¤„ç†videoæ ‡ç­¾å†…çš„sourceå…ƒç´ 
                        for source in element.find_all('source'):
                            video_src = source.get('src')
                            if video_src:
                                video_url = urljoin(self.base_url, video_src)
                                result_data.append({"type": "video", "value": video_url})
                    
                    elif element.name in ['pre', 'code']:
                        code_text = element.get_text().strip()
                        if code_text:
                            result_data.append({"type": "code", "value": code_text})
                
                except Exception as e:
                    logger.warning(f"âš ï¸ [OpenHarmonyåšå®¢] è§£æå…ƒç´ å¤±è´¥: {e}")
                    continue
        
        logger.info(f"ğŸ“ [OpenHarmonyåšå®¢] è§£ææ–‡ç« å†…å®¹å®Œæˆï¼Œå…± {len(result_data)} ä¸ªå†…å®¹å—: {article_url}")
        return result_data

    def _format_article(self, article):
        """å°†æ–‡ç« æ ¼å¼åŒ–ä¸ºç»Ÿä¸€çš„æ–°é—»æ ¼å¼ï¼Œä¸OpenHarmonyçˆ¬è™«ä¿æŒä¸€è‡´"""
        import hashlib
        
        # ç”Ÿæˆæ–‡ç« IDï¼ˆåŸºäºURLçš„å“ˆå¸Œï¼Œä¸OpenHarmonyçˆ¬è™«ä¿æŒä¸€è‡´çš„16ä½é•¿åº¦ï¼‰
        article_id = hashlib.md5(article['url'].encode()).hexdigest()[:16]
        
        # è¿”å›ç»Ÿä¸€æ ¼å¼ï¼Œç¬¦åˆTypeScriptæ¥å£è§„èŒƒ
        return {
            "id": article_id,
            "title": article['title'],
            "date": article.get('date', ''),
            "url": article['url'],
            "content": article.get('content', []),
            "category": "æŠ€æœ¯åšå®¢",  # åŒºåˆ«äºå®˜æ–¹åŠ¨æ€
            "summary": article.get('summary', ''),
            "source": "OpenHarmonyæŠ€æœ¯åšå®¢",  # æ˜ç¡®æ ‡æ³¨æ¥æº
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat()
        }

    def crawl_openharmony_blog_news(self, batch_callback=None, batch_size=20):
        """
        çˆ¬å–OpenHarmonyæŠ€æœ¯åšå®¢æ–°é—»ï¼Œå®Œå…¨ä»¿ç…§OpenHarmonyçˆ¬è™«çš„é€»è¾‘
        
        Args:
            batch_callback: åˆ†æ‰¹å¤„ç†å›è°ƒå‡½æ•°
            batch_size: æ¯æ‰¹å¤„ç†çš„æ–‡ç« æ•°é‡
            
        Returns:
            å¤„ç†åçš„æ–‡ç« åˆ—è¡¨
        """
        logger.info("ğŸš€ [OpenHarmonyåšå®¢] å¼€å§‹çˆ¬å–OpenHarmonyæŠ€æœ¯åšå®¢æ–°é—»...")
        if batch_callback:
            logger.info(f"ğŸ“¦ [OpenHarmonyåšå®¢] å¯ç”¨åˆ†æ‰¹å¤„ç†æ¨¡å¼ï¼Œæ¯ {batch_size} ç¯‡æ–‡ç« æ‰§è¡Œä¸€æ¬¡å›è°ƒ")
        
        # 1. è·å–æ‰€æœ‰æ–‡ç« ä¿¡æ¯
        articles_info = self.get_all_blog_articles()
        logger.info(f"ğŸ“‹ [OpenHarmonyåšå®¢] è·å–åˆ° {len(articles_info)} ç¯‡æ–‡ç« ä¿¡æ¯")
        
        if not articles_info:
            logger.warning("âš ï¸ [OpenHarmonyåšå®¢] æœªè·å–åˆ°ä»»ä½•æ–‡ç« ä¿¡æ¯")
            return []
        
        # 2. é€ç¯‡å¤„ç†æ–‡ç« å†…å®¹ï¼Œå®Œå…¨ä»¿ç…§OpenHarmonyçˆ¬è™«çš„é€»è¾‘
        all_articles_data = []
        batch_articles = []
        
        for i, info in enumerate(articles_info):
            title = info["title"]
            date = info["date"]
            article_url = info["url"]
            summary = info.get("summary", "")
            
            logger.info(f"ğŸ” [OpenHarmonyåšå®¢] æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{len(articles_info)} ç¯‡æ–‡ç« : {title}")
            logger.debug(f"ğŸ”— [OpenHarmonyåšå®¢] æ–‡ç« URL: {article_url}")
            
            # è§£ææ–‡ç« è¯¦ç»†å†…å®¹
            article_data = self.parse_article_content(article_url)
            if article_data:
                # ä½¿ç”¨_format_articleæ–¹æ³•æ ¼å¼åŒ–æ•°æ®ï¼Œç¡®ä¿ä¸OpenHarmonyçˆ¬è™«ä¸€è‡´
                article_info = self._format_article({
                    "title": title,
                    "date": date,
                    "url": article_url,
                    "content": article_data,
                    "summary": summary
                })
                all_articles_data.append(article_info)
                batch_articles.append(article_info)
                logger.info(f"âœ… [OpenHarmonyåšå®¢] æˆåŠŸè§£ææ–‡ç« ï¼Œå…± {len(article_data)} ä¸ªå†…å®¹å—")
                
                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ‰¹å¤„ç†å¤§å°
                if len(batch_articles) >= batch_size and batch_callback:
                    try:
                        logger.info(f"ğŸ“¦ [OpenHarmonyåšå®¢åˆ†æ‰¹å¤„ç†] è¾¾åˆ°æ‰¹å¤„ç†å¤§å° {batch_size}ï¼Œæ‰§è¡Œå›è°ƒ...")
                        batch_callback(batch_articles.copy())
                        batch_articles.clear()  # æ¸…ç©ºå½“å‰æ‰¹æ¬¡
                        logger.info(f"âœ… [OpenHarmonyåšå®¢åˆ†æ‰¹å¤„ç†] å›è°ƒæ‰§è¡ŒæˆåŠŸï¼Œç»§ç»­å¤„ç†åç»­æ–‡ç« ")
                    except Exception as callback_e:
                        logger.error(f"âŒ [OpenHarmonyåšå®¢åˆ†æ‰¹å¤„ç†] å›è°ƒæ‰§è¡Œå¤±è´¥: {callback_e}")
            else:
                logger.warning(f"âš ï¸ [OpenHarmonyåšå®¢] æ–‡ç« å†…å®¹è§£æå¤±è´¥: {title}")
            
            # æ·»åŠ è¯·æ±‚é—´éš”ï¼Œé¿å…è¿‡äºé¢‘ç¹
            time.sleep(1)
        
        # å¤„ç†å‰©ä½™çš„æ‰¹æ¬¡
        if batch_articles and batch_callback:
            try:
                logger.info(f"ğŸ“¦ [OpenHarmonyåšå®¢åˆ†æ‰¹å¤„ç†] å¤„ç†æœ€åå‰©ä½™çš„ {len(batch_articles)} ç¯‡æ–‡ç« ...")
                batch_callback(batch_articles.copy())
                logger.info(f"âœ… [OpenHarmonyåšå®¢åˆ†æ‰¹å¤„ç†] æœ€åæ‰¹æ¬¡å¤„ç†å®Œæˆ")
            except Exception as callback_e:
                logger.error(f"âŒ [OpenHarmonyåšå®¢åˆ†æ‰¹å¤„ç†] æœ€åæ‰¹æ¬¡å¤„ç†å¤±è´¥: {callback_e}")
        
        logger.info(f"ğŸ‰ [OpenHarmonyåšå®¢] çˆ¬å–å®Œæˆï¼Œå…±å¤„ç† {len(all_articles_data)} ç¯‡æ–‡ç« ")
        return all_articles_data

    def validate_articles(self, articles: List[Dict]) -> List[Dict]:
        """
        éªŒè¯æ–‡ç« æ•°æ®å®Œæ•´æ€§
        """
        valid_articles = []
        
        for article in articles:
            try:
                # æ£€æŸ¥å¿…è¦å­—æ®µ
                required_fields = ['id', 'title', 'url', 'content', 'source']
                if not all(field in article for field in required_fields):
                    logger.warning(f"âš ï¸ [OpenHarmonyåšå®¢] æ–‡ç« ç¼ºå°‘å¿…è¦å­—æ®µ: {article.get('title', 'æœªçŸ¥æ ‡é¢˜')}")
                    continue
                
                # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©º
                if not article.get('content') or len(article.get('content', [])) == 0:
                    logger.warning(f"âš ï¸ [OpenHarmonyåšå®¢] æ–‡ç« å†…å®¹ä¸ºç©º: {article.get('title', 'æœªçŸ¥æ ‡é¢˜')}")
                    continue
                
                # æ£€æŸ¥URLæœ‰æ•ˆæ€§
                if not article.get('url') or not article['url'].startswith('http'):
                    logger.warning(f"âš ï¸ [OpenHarmonyåšå®¢] æ–‡ç« URLæ— æ•ˆ: {article.get('title', 'æœªçŸ¥æ ‡é¢˜')}")
                    continue
                
                valid_articles.append(article)
                
            except Exception as e:
                logger.error(f"âŒ [OpenHarmonyåšå®¢] éªŒè¯æ–‡ç« æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                continue
        
        logger.info(f"âœ… [OpenHarmonyåšå®¢] æ–‡ç« éªŒè¯å®Œæˆï¼Œæœ‰æ•ˆæ–‡ç« : {len(valid_articles)}/{len(articles)}")
        return valid_articles
