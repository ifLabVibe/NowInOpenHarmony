# Copyright (c) 2025 XBXyftx
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import requests
from bs4 import BeautifulSoup
import os
import time
from urllib.parse import urljoin, urlparse
from datetime import datetime
import logging

class OpenHarmonyImageCrawler:
    """OpenHarmonyå®˜ç½‘bannerå›¾ç‰‡çˆ¬è™«"""
    
    def __init__(self, download_path="./downloads/images"):
        self.base_url = "https://old.openharmony.cn"
        self.target_url = "https://old.openharmony.cn/mainPlay/"
        self.download_path = download_path
        self.session = requests.Session()
        
        # è®¾ç½®æ‰‹æœºç‰ˆUser-Agent
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_7_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Mobile/15E148 Safari/604.1',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0'
        })
        
        # åˆ›å»ºä¸‹è½½ç›®å½•
        os.makedirs(self.download_path, exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—
        self.logger = logging.getLogger(__name__)
    
    def get_page_content(self, url):
        """è·å–é¡µé¢å†…å®¹"""
        try:
            self.logger.info(f"ğŸŒ æ­£åœ¨è·å–é¡µé¢: {url}")
            response = self.session.get(url, timeout=15)
            response.raise_for_status()
            response.encoding = 'utf-8'
            self.logger.info(f"âœ… é¡µé¢è·å–æˆåŠŸï¼ŒçŠ¶æ€ç : {response.status_code}")
            return response.text
        except Exception as e:
            self.logger.error(f"âŒ è·å–é¡µé¢å¤±è´¥: {url}, é”™è¯¯: {e}")
            return None
    
    def find_banner_images(self, html_content):
        """æŸ¥æ‰¾é¡µé¢ä¸­æ‰€æœ‰classä¸ºbanner-imgçš„å›¾ç‰‡"""
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # æŸ¥æ‰¾æ‰€æœ‰classåŒ…å«banner-imgçš„imgæ ‡ç­¾
        banner_images = soup.find_all('img', class_=lambda x: x and 'banner-img' in x)
        
        image_urls = []
        for img in banner_images:
            # è·å–å›¾ç‰‡URLï¼Œä¼˜å…ˆçº§ï¼šdata-src > data-original > src
            img_src = (
                img.get('data-src') or 
                img.get('data-original') or 
                img.get('src')
            )
            
            if img_src:
                # è½¬æ¢ä¸ºç»å¯¹URL
                full_url = urljoin(self.base_url, img_src)
                
                # è·å–å›¾ç‰‡çš„altå±æ€§ä½œä¸ºæè¿°
                alt_text = img.get('alt', '')
                
                # è·å–å›¾ç‰‡çš„å…¶ä»–å±æ€§
                img_class = img.get('class', [])
                img_id = img.get('id', '')
                
                image_info = {
                    'url': full_url,
                    'alt': alt_text,
                    'class': img_class,
                    'id': img_id,
                    'original_src': img_src
                }
                
                image_urls.append(image_info)
                self.logger.info(f"ğŸ–¼ï¸  å‘ç°bannerå›¾ç‰‡: {alt_text or 'æ— æè¿°'} - {full_url}")
        
        self.logger.info(f"ğŸ“Š å…±å‘ç° {len(image_urls)} å¼ bannerå›¾ç‰‡")
        return image_urls
    
    def download_image(self, image_info):
        """ä¸‹è½½å•å¼ å›¾ç‰‡"""
        url = image_info['url']
        alt_text = image_info['alt']
        
        try:
            self.logger.info(f"â¬‡ï¸  æ­£åœ¨ä¸‹è½½å›¾ç‰‡: {alt_text or 'æ— æè¿°'}")
            
            # è·å–æ–‡ä»¶å
            parsed_url = urlparse(url)
            filename = os.path.basename(parsed_url.path)
            
            # å¦‚æœæ²¡æœ‰æ–‡ä»¶æ‰©å±•åï¼Œå°è¯•ä»Content-Typeæ¨æ–­
            if not filename or '.' not in filename:
                head_response = self.session.head(url, timeout=10)
                content_type = head_response.headers.get('content-type', '')
                if 'jpeg' in content_type or 'jpg' in content_type:
                    filename = f"banner_image_{int(time.time())}.jpg"
                elif 'png' in content_type:
                    filename = f"banner_image_{int(time.time())}.png"
                elif 'gif' in content_type:
                    filename = f"banner_image_{int(time.time())}.gif"
                elif 'webp' in content_type:
                    filename = f"banner_image_{int(time.time())}.webp"
                else:
                    filename = f"banner_image_{int(time.time())}.jpg"
            
            # æ„å»ºå®Œæ•´çš„æ–‡ä»¶è·¯å¾„
            file_path = os.path.join(self.download_path, filename)
            
            # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ æ—¶é—´æˆ³é¿å…é‡å¤
            if os.path.exists(file_path):
                name, ext = os.path.splitext(filename)
                filename = f"{name}_{int(time.time())}{ext}"
                file_path = os.path.join(self.download_path, filename)
            
            # ä¸‹è½½å›¾ç‰‡
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            
            # ä¿å­˜å›¾ç‰‡
            with open(file_path, 'wb') as f:
                f.write(response.content)
            
            file_size = len(response.content)
            self.logger.info(f"âœ… å›¾ç‰‡ä¸‹è½½æˆåŠŸ: {filename} ({file_size} bytes)")
            
            return {
                'status': 'success',
                'filename': filename,
                'file_path': file_path,
                'file_size': file_size,
                'url': url,
                'alt': alt_text
            }
            
        except Exception as e:
            self.logger.error(f"âŒ å›¾ç‰‡ä¸‹è½½å¤±è´¥: {url}, é”™è¯¯: {e}")
            return {
                'status': 'failed',
                'url': url,
                'alt': alt_text,
                'error': str(e)
            }
    
    def crawl_banner_images(self):
        """çˆ¬å–æ‰€æœ‰bannerå›¾ç‰‡"""
        self.logger.info("ğŸš€ å¼€å§‹çˆ¬å–OpenHarmonyå®˜ç½‘bannerå›¾ç‰‡...")
        self.logger.info(f"ğŸ¯ ç›®æ ‡é¡µé¢: {self.target_url}")
        self.logger.info(f"ğŸ“± ä½¿ç”¨æ‰‹æœºç‰ˆUser-Agent")
        self.logger.info(f"ğŸ“ ä¸‹è½½ç›®å½•: {self.download_path}")
        
        # è·å–é¡µé¢å†…å®¹
        html_content = self.get_page_content(self.target_url)
        if not html_content:
            self.logger.error("âŒ æ— æ³•è·å–é¡µé¢å†…å®¹ï¼Œçˆ¬å–ç»ˆæ­¢")
            return []
        
        # æŸ¥æ‰¾bannerå›¾ç‰‡
        image_infos = self.find_banner_images(html_content)
        if not image_infos:
            self.logger.warning("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•bannerå›¾ç‰‡")
            return []
        
        # ä¸‹è½½å›¾ç‰‡
        download_results = []
        for i, image_info in enumerate(image_infos, 1):
            self.logger.info(f"ğŸ“¥ å¤„ç†ç¬¬ {i}/{len(image_infos)} å¼ å›¾ç‰‡...")
            result = self.download_image(image_info)
            download_results.append(result)
            
            # æ·»åŠ å»¶æ—¶é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            time.sleep(1)
        
        # ç»Ÿè®¡ç»“æœ
        successful_downloads = [r for r in download_results if r['status'] == 'success']
        failed_downloads = [r for r in download_results if r['status'] == 'failed']
        
        self.logger.info(f"ğŸ‰ çˆ¬å–å®Œæˆï¼")
        self.logger.info(f"âœ… æˆåŠŸä¸‹è½½: {len(successful_downloads)} å¼ å›¾ç‰‡")
        self.logger.info(f"âŒ ä¸‹è½½å¤±è´¥: {len(failed_downloads)} å¼ å›¾ç‰‡")
        
        if successful_downloads:
            self.logger.info("ğŸ“‹ æˆåŠŸä¸‹è½½çš„å›¾ç‰‡:")
            for result in successful_downloads:
                self.logger.info(f"  - {result['filename']} ({result['file_size']} bytes)")
        
        if failed_downloads:
            self.logger.info("âŒ ä¸‹è½½å¤±è´¥çš„å›¾ç‰‡:")
            for result in failed_downloads:
                self.logger.info(f"  - {result['url']} (é”™è¯¯: {result['error']})")
        
        return download_results
    
    def get_banner_image_info(self):
        """åªè·å–bannerå›¾ç‰‡ä¿¡æ¯ï¼Œä¸ä¸‹è½½"""
        self.logger.info("ğŸ” è·å–OpenHarmonyå®˜ç½‘bannerå›¾ç‰‡ä¿¡æ¯...")
        
        html_content = self.get_page_content(self.target_url)
        if not html_content:
            return []
        
        return self.find_banner_images(html_content)


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºçˆ¬è™«ä½¿ç”¨"""
    print("ğŸ¯ OpenHarmonyå®˜ç½‘Bannerå›¾ç‰‡çˆ¬è™«")
    print("=" * 50)
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('banner_crawler.log', encoding='utf-8')
        ]
    )
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    crawler = OpenHarmonyImageCrawler(download_path="./banner_images")
    
    try:
        # çˆ¬å–å¹¶ä¸‹è½½å›¾ç‰‡
        results = crawler.crawl_banner_images()
        
        if results:
            print(f"\nğŸ“Š çˆ¬å–ç»“æœç»Ÿè®¡:")
            successful = sum(1 for r in results if r['status'] == 'success')
            failed = sum(1 for r in results if r['status'] == 'failed')
            print(f"  âœ… æˆåŠŸ: {successful} å¼ ")
            print(f"  âŒ å¤±è´¥: {failed} å¼ ")
            print(f"  ğŸ“ ä¿å­˜ä½ç½®: {crawler.download_path}")
        else:
            print("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•bannerå›¾ç‰‡")
            
    except Exception as e:
        print(f"âŒ çˆ¬å–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
